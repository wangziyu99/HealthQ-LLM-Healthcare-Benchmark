"""
Judge module for evaluating LLM-generated medical questions.

This module defines a function to assess the quality of generated questions based on various 
metrics such as specificity, usefulness, relevance, coverage, and fluency.
"""

import os
from langchain.output_parsers import ResponseSchema, StructuredOutputParser
from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser
from langchain.prompts import PromptTemplate
from langchain.schema.output_parser import StrOutputParser
from langchain_core.callbacks import StdOutCallbackHandler
from langchain.callbacks.tracers import ConsoleCallbackHandler
from typing import List, Tuple
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.docstore.document import Document
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from langchain import PromptTemplate, LLMChain
from langchain.chains.base import Chain

# ================================
# ENVIRONMENT VARIABLES
# ================================

# Set API keys for external LLM services (should be securely managed in production)
os.environ["GROQ_API_KEY"] = "YOUR API KEY"
os.environ["ANTHROPIC_API_KEY"] = "YOUR API KEY"

# Initialize callback handler for LangChain debugging
handler = ConsoleCallbackHandler()

# ================================
# JUDGING FUNCTION
# ================================

def judge(patient_known_knowledge, patient_in, system_question, llm):
    """
    Evaluates the quality of a generated medical question based on key metrics.

    Args:
        patient_known_knowledge (str): The patient's known symptoms and medical history.
        patient_in (str): The patient's initial statement given to the system.
        system_question (str): The question generated by the system.
        llm (LLMChain): The language model used for evaluation.

    Returns:
        dict: A dictionary containing scores for each evaluation metric.
    """

    # Define evaluation metrics for LLM-based question assessment
    response_schemas = [
        ResponseSchema(
            name="Specificity",
            description="How specific is the question asked? Rate from 1-10",
            type="string"
        ),
        ResponseSchema(
            name="Usefulness",
            description="How useful is the question asked? Rate from 1-10",
            type="string"
        ),
        ResponseSchema(
            name="Relevance",
            description="How relevant is the new question to the patient's symptom? Rate from 1-10",
            type="string"
        ),
        ResponseSchema(
            name="Coverage",
            description="How much does this new question cover the information from the full ground truth data? Rate from 1-10",
            type="string"
        ),
        ResponseSchema(
            name="Fluency",
            description="How fluent and human-friendly is this question? Rate from 1-10",
            type="string"
        ),
        ResponseSchema(
            name="Comments",
            description="Additional comments on the system-generated question.",
            type="string"
        ),
    ]

    # Initialize output parser for structured evaluation
    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)
    format_instructions = output_parser.get_format_instructions()

    # Define the evaluation prompt template
    template = """
    "
    {patient_known_knowledge}
    " 
    Above is all the information the patient knows.
    
    The patient provides the system with this information:
    {patient_in}

    The system generates the following question:
    {system_question}

    Using this information, evaluate the system-generated question based on the following criteria:
    - Specificity: Does the question precisely address the patient's symptoms or medical condition?
    - Usefulness: Is the question helpful in eliciting diagnostically relevant details?
    - Relevance: How well does the question align with the patient's symptoms and medical history?
    - Coverage: Does the question cover a wide range of relevant details, or is it too narrow?
    - Fluency: Is the question grammatically correct and naturally phrased?

    Assign a score from 1 to 10 for each metric.
    {format_instructions}
    """

    # Create a LangChain prompt object
    prompt = PromptTemplate(
        input_variables=["patient_known_knowledge", "patient_in", "system_question"],
        template=template,
        partial_variables={"format_instructions": format_instructions},
    )

    # Define an LLM processing chain
    chain = prompt | llm | output_parser

    # Execute the evaluation process and return the results
    return chain.invoke(
        input={"patient_known_knowledge": patient_known_knowledge,
               "patient_in": patient_in,
               "system_question": system_question},
        config={'callbacks': [handler]}
    )
